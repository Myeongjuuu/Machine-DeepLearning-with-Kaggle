{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일 구조 설정 및 Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 압축 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!unzip -qq /kaggle/input/dogs-vs-cats/train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 분할 및 디렉토리 구조 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\kaggle\\working\\cats_vs_dogs_small\\train\\cat\n",
      "\\kaggle\\working\\cats_vs_dogs_small\\train\\dog\n",
      "\\kaggle\\working\\cats_vs_dogs_small\\validation\\cat\n",
      "\\kaggle\\working\\cats_vs_dogs_small\\validation\\dog\n",
      "\\kaggle\\working\\cats_vs_dogs_small\\test\\cat\n",
      "\\kaggle\\working\\cats_vs_dogs_small\\test\\dog\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, pathlib\n",
    "\n",
    "original_dir = pathlib.Path(\"/kaggle/working/train\")\n",
    "new_base_dir = pathlib.Path(\"/kaggle/working/cats_vs_dogs_small\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        print(dir)\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# 180x180 크기의 RGB 이미지를 입력으로 받음\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "\n",
    "# 입력 이미지를 정규화하여 0~1 범위의 값으로 변환\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "# convolution 및 pooling layer 설정\n",
    "# Conv2D Layer, MaxPooling2D Layer\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "\n",
    "# Flatten Layer\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# 이진 분류를 위해 sigmoid activation function 사용\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function: binary_crossentropy를 사용\n",
    "# optimizer: rmsprop을 사용하여 모델을 최적화\n",
    "# Performance Metrics : 정확도(accuracy)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 디렉토리에서 이미지 데이터 로드\n",
    "# train, val, test dataset으로 만들기\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 369ms/step - accuracy: 0.6012 - loss: 0.6728 - val_accuracy: 0.6630 - val_loss: 0.6201\n",
      "Epoch 2/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 421ms/step - accuracy: 0.6333 - loss: 0.6348 - val_accuracy: 0.6660 - val_loss: 0.6108\n",
      "Epoch 3/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 481ms/step - accuracy: 0.6697 - loss: 0.6107 - val_accuracy: 0.6810 - val_loss: 0.5997\n",
      "Epoch 4/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 672ms/step - accuracy: 0.6984 - loss: 0.5766 - val_accuracy: 0.6910 - val_loss: 0.5585\n",
      "Epoch 5/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 830ms/step - accuracy: 0.7073 - loss: 0.5672 - val_accuracy: 0.7110 - val_loss: 0.5789\n",
      "Epoch 6/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 786ms/step - accuracy: 0.7141 - loss: 0.5546 - val_accuracy: 0.6820 - val_loss: 0.6308\n",
      "Epoch 7/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 742ms/step - accuracy: 0.7708 - loss: 0.4699 - val_accuracy: 0.6880 - val_loss: 0.6019\n",
      "Epoch 8/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 736ms/step - accuracy: 0.7993 - loss: 0.4428 - val_accuracy: 0.6860 - val_loss: 0.6009\n",
      "Epoch 9/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 722ms/step - accuracy: 0.8198 - loss: 0.4011 - val_accuracy: 0.7160 - val_loss: 0.6621\n",
      "Epoch 10/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 664ms/step - accuracy: 0.8371 - loss: 0.3756 - val_accuracy: 0.7080 - val_loss: 0.7465\n"
     ]
    }
   ],
   "source": [
    "# callback : 가장 성능이 좋은 모델(가장 낮은 검증 손실을 기록한 모델)을 저장\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_from_scratch.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
