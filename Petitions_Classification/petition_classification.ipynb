{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>count</th>\n",
       "      <th>end</th>\n",
       "      <th>start</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>인권/성평등</td>\n",
       "      <td>본인은 2019년 8월 경 서울지방병무청 제1검사장 탈의실에서 믿을 수 없는 것을 ...</td>\n",
       "      <td>267</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>서울지방병무청 탈의실에 설치된 CCTV에 대한 진상규명을 요구한다. 또한 인권위의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경제민주화</td>\n",
       "      <td>우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저...</td>\n",
       "      <td>271</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>주식시장 활성화 및 소액(개미)투자자 보호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>행정</td>\n",
       "      <td>억울한 일로 국민청원을 신청합니다.\\r\\n\\r\\n\\r\\n 저는 **구치소 **교도관...</td>\n",
       "      <td>198</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>교정기관의 민낮</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>안전/환경</td>\n",
       "      <td>미세먼지의 심각성은 이제 적극적인 대안을 요구 하고 있습니다.\\r\\n\\r\\n우리 일...</td>\n",
       "      <td>170</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>미세먼지 저감 대책</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>교통/건축/국토</td>\n",
       "      <td>저는 우선 아이셋의 부모입니다.\\r\\n\\r\\n식구가 많은편이고 아이들이 성장함에 따...</td>\n",
       "      <td>2,127</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>악질세입자 방지를 위한 세입자보호법을 재정해주세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10876</th>\n",
       "      <td>기타</td>\n",
       "      <td>**** 신용점수제는 전면 재검토해야 합니다\\r\\n\\r\\n\\r\\n신용점수제의 도입취...</td>\n",
       "      <td>521</td>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>****의 신용점수제는 대국민 사기극!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10877</th>\n",
       "      <td>교통/건축/국토</td>\n",
       "      <td>저는 서울 시민입니다 당연히 마을버스도 이용하고 있습니다 마을버스 승객은 40%가 ...</td>\n",
       "      <td>333</td>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>서울 마을버스 업체 지원 정부에서 해결해주세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10878</th>\n",
       "      <td>정치개혁</td>\n",
       "      <td>광복 이래 역사를 말할 것도 없고, 근래에 들어서도 수많은 사건들이 공직자들에 의해...</td>\n",
       "      <td>1,557</td>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>과거사위원회를 상설기구로 설치하여 주십시오.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879</th>\n",
       "      <td>보건복지</td>\n",
       "      <td>의사들은 코로나로 가장 위급한 시기에 국민에 생명을 잡고 파업을 하였습니다     ...</td>\n",
       "      <td>18,205</td>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>정부와 보건복지부에 요청 합니다 의대생 국시 절대 반대 합니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10880</th>\n",
       "      <td>보건복지</td>\n",
       "      <td>안녕하세요.\\r\\n\\r\\n\\r\\n오늘 정부가 내년 의사 국가고시를 1월에 실시하는 ...</td>\n",
       "      <td>6,299</td>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>내년 의사 국가고시를 1월에 추가로 실시하면서 정부를 믿고 올해 응시한 423명을 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10881 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                            content   count  \\\n",
       "0        인권/성평등  본인은 2019년 8월 경 서울지방병무청 제1검사장 탈의실에서 믿을 수 없는 것을 ...     267   \n",
       "1         경제민주화  우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저...     271   \n",
       "2            행정  억울한 일로 국민청원을 신청합니다.\\r\\n\\r\\n\\r\\n 저는 **구치소 **교도관...     198   \n",
       "3         안전/환경  미세먼지의 심각성은 이제 적극적인 대안을 요구 하고 있습니다.\\r\\n\\r\\n우리 일...     170   \n",
       "4      교통/건축/국토  저는 우선 아이셋의 부모입니다.\\r\\n\\r\\n식구가 많은편이고 아이들이 성장함에 따...   2,127   \n",
       "...         ...                                                ...     ...   \n",
       "10876        기타  **** 신용점수제는 전면 재검토해야 합니다\\r\\n\\r\\n\\r\\n신용점수제의 도입취...     521   \n",
       "10877  교통/건축/국토  저는 서울 시민입니다 당연히 마을버스도 이용하고 있습니다 마을버스 승객은 40%가 ...     333   \n",
       "10878      정치개혁  광복 이래 역사를 말할 것도 없고, 근래에 들어서도 수많은 사건들이 공직자들에 의해...   1,557   \n",
       "10879      보건복지  의사들은 코로나로 가장 위급한 시기에 국민에 생명을 잡고 파업을 하였습니다     ...  18,205   \n",
       "10880      보건복지  안녕하세요.\\r\\n\\r\\n\\r\\n오늘 정부가 내년 의사 국가고시를 1월에 실시하는 ...   6,299   \n",
       "\n",
       "              end       start  \\\n",
       "0      2020-02-01  2020-01-02   \n",
       "1      2020-02-01  2020-01-02   \n",
       "2      2020-02-01  2020-01-02   \n",
       "3      2020-02-01  2020-01-02   \n",
       "4      2020-02-01  2020-01-02   \n",
       "...           ...         ...   \n",
       "10876  2021-01-30  2020-12-31   \n",
       "10877  2021-01-30  2020-12-31   \n",
       "10878  2021-01-30  2020-12-31   \n",
       "10879  2021-01-30  2020-12-31   \n",
       "10880  2021-01-30  2020-12-31   \n",
       "\n",
       "                                                   title  \n",
       "0      서울지방병무청 탈의실에 설치된 CCTV에 대한 진상규명을 요구한다. 또한 인권위의 ...  \n",
       "1                                주식시장 활성화 및 소액(개미)투자자 보호  \n",
       "2                                               교정기관의 민낮  \n",
       "3                                             미세먼지 저감 대책  \n",
       "4                           악질세입자 방지를 위한 세입자보호법을 재정해주세요.  \n",
       "...                                                  ...  \n",
       "10876                              ****의 신용점수제는 대국민 사기극!  \n",
       "10877                          서울 마을버스 업체 지원 정부에서 해결해주세요  \n",
       "10878                           과거사위원회를 상설기구로 설치하여 주십시오.  \n",
       "10879                 정부와 보건복지부에 요청 합니다 의대생 국시 절대 반대 합니다  \n",
       "10880  내년 의사 국가고시를 1월에 추가로 실시하면서 정부를 믿고 올해 응시한 423명을 ...  \n",
       "\n",
       "[10881 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"C:/Users/windows/Desktop/Petitions Classification/data/crawling.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저평가된 시장이라고 합니다. 하지만 투자매력이 없다고도 합니다.이렇게 말하는 이유가 어디 있습니까? 바로 투자를 해도 수익을 기대하기 어렵다는 인식이 이미 널리 퍼져 있다는 것입니다.\\r\\n\\r\\n\\r\\n지금은 투자매력이 없어서 그렇지,..우리 나라 시중 부동 자금이 어마어마 한 것으로 알려진 것과, 외국 투자 자본 또한 실로 어마무지하게 많다는 것도 알고있습니다. 그러나 이 투자금이 주식시장으로 원활하게 순환이 안되고 있다는데 있습니다.\\r\\n\\r\\n\\r\\n정부는 유휴자금이 주식 시장으로 들어오게 분위기를 띄어줘야 하는데,... 그렇지 못한 현실이 안타깝다고 생각합니다.\\r\\n\\r\\n국가가 지원해 돈 들이기가 어려우면,정부에서 정서적인 말이라도 활성화를 위한 관심표명과 정책적으로 지원만 해도 시장분위기는 많이 좋아질 것이라 확신합니다. \\r\\n\\r\\n\\r\\n그래서 저는 정부에 다음과 같이 청원합니다.\\r\\n\\r\\n주식시장에 더 큰 충격 오기 전에 정부가 예방 조치를 할 수 있는데까지 노력해 주시기를 당부 드리면서,...\\r\\n\\r\\n\\r\\n첫째,주식시장 활성화와 부양에 대한 정부의 의지를 표명해 주십시오 \\r\\n\\r\\n\\r\\n둘째,  코스닥 종목은 공매도 제외시켜 주세요.\\r\\n\\r\\n\\r\\n공매도 제도를 아예 없애버리면 좋겠지만 제도를 살린다면 적용 시장에서 코스닥 종목은 제외 해 주어야 체력이 약한 코스닥 시장을 안정시킬 수 있다고 봅니다 \\r\\n\\r\\n\\r\\n셋째, 거래시장의 주식거래세를 더 낮춰 주세요 \\r\\n\\r\\n\\r\\n특히 개미(소액)투자에 동일한 요율로 부과하는 것은 너무나 불공정 하다고 봅니다.\\r\\n\\r\\n\\r\\n넷째, 중,장기 보유자에 대한 우대 차원에서 보유기간을 설정하여 주세요.\\r\\n\\r\\n\\r\\n이는 장기 보유자에 대한 혜택을 주어 초단타매매 등 시장 질서를 교란하는 투자자와 분리하는 제도를 도입해 시장 안정화에 기여해 주시길 간곡히 부탁드리면서 청원합니다.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before Preprocessing\n",
    "df.loc[1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 특정 공백 문자(\\t, \\r, \\n, \\f, \\v)를 공백 문자 ' '로 변환\n",
    "def remove_white_space(text):\n",
    "    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "# 한글, 숫자, 공백을 제외한 모든 특수 문자를 공백 문자 ' '로 변환\n",
    "def remove_special_char(text):\n",
    "    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9]+', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "df.title = df.title.apply(remove_white_space)\n",
    "df.title = df.title.apply(remove_special_char)\n",
    "\n",
    "df.content = df.content.apply(remove_white_space)\n",
    "df.content = df.content.apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저평가된 시장이라고 합니다  하지만 투자매력이 없다고도 합니다 이렇게 말하는 이유가 어디 있습니까  바로 투자를 해도 수익을 기대하기 어렵다는 인식이 이미 널리 퍼져 있다는 것입니다       지금은 투자매력이 없어서 그렇지 우리 나라 시중 부동 자금이 어마어마 한 것으로 알려진 것과  외국 투자 자본 또한 실로 어마무지하게 많다는 것도 알고있습니다  그러나 이 투자금이 주식시장으로 원활하게 순환이 안되고 있다는데 있습니다       정부는 유휴자금이 주식 시장으로 들어오게 분위기를 띄어줘야 하는데  그렇지 못한 현실이 안타깝다고 생각합니다     국가가 지원해 돈 들이기가 어려우면 정부에서 정서적인 말이라도 활성화를 위한 관심표명과 정책적으로 지원만 해도 시장분위기는 많이 좋아질 것이라 확신합니다        그래서 저는 정부에 다음과 같이 청원합니다     주식시장에 더 큰 충격 오기 전에 정부가 예방 조치를 할 수 있는데까지 노력해 주시기를 당부 드리면서       첫째 주식시장 활성화와 부양에 대한 정부의 의지를 표명해 주십시오       둘째   코스닥 종목은 공매도 제외시켜 주세요       공매도 제도를 아예 없애버리면 좋겠지만 제도를 살린다면 적용 시장에서 코스닥 종목은 제외 해 주어야 체력이 약한 코스닥 시장을 안정시킬 수 있다고 봅니다       셋째  거래시장의 주식거래세를 더 낮춰 주세요       특히 개미 소액 투자에 동일한 요율로 부과하는 것은 너무나 불공정 하다고 봅니다       넷째  중 장기 보유자에 대한 우대 차원에서 보유기간을 설정하여 주세요       이는 장기 보유자에 대한 혜택을 주어 초단타매매 등 시장 질서를 교란하는 투자자와 분리하는 제도를 도입해 시장 안정화에 기여해 주시길 간곡히 부탁드리면서 청원합니다 '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after Preprocessing\n",
    "df.loc[1]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing 및 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from konlpy) (1.5.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from konlpy) (5.3.0)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from konlpy) (1.24.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\pknu\\appdata\\roaming\\python\\python38\\site-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "df['title_token'] = df.title.apply(okt.morphs)\n",
    "df['content_token'] = df.content.apply(okt.nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category         object\n",
      "content          object\n",
      "count             int64\n",
      "end              object\n",
      "start            object\n",
      "title            object\n",
      "title_token      object\n",
      "content_token    object\n",
      "token_final      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['token_final'] = df.title_token + df.content_token\n",
    "\n",
    "df['count'] = df['count'].replace({',' : ''}, regex = True).apply(lambda x : int(x))\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "df['label'] = df['count'].apply(lambda x: 'Yes' if x>=1000 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_final</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[서울, 지방, 병무청, 탈의실, 에, 설치, 된, 에, 대한, 진상, 규명, 을,...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[주식시장, 활성화, 및, 소액, 개미, 투자자, 보호, 우리, 나라, 코스피, 총...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[교정, 기관, 의, 민낮, 일로, 국민, 청원, 신청, 저, 구치소, 교도관, 이...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[미세먼지, 저, 감, 대책, 미세먼지, 심각, 성은, 이제, 적극, 대안, 요구,...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[악질, 세, 입자, 방지, 를, 위, 한, 세, 입자, 보호, 법, 을, 재정, ...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         token_final label\n",
       "0  [서울, 지방, 병무청, 탈의실, 에, 설치, 된, 에, 대한, 진상, 규명, 을,...    No\n",
       "1  [주식시장, 활성화, 및, 소액, 개미, 투자자, 보호, 우리, 나라, 코스피, 총...    No\n",
       "2  [교정, 기관, 의, 민낮, 일로, 국민, 청원, 신청, 저, 구치소, 교도관, 이...    No\n",
       "3  [미세먼지, 저, 감, 대책, 미세먼지, 심각, 성은, 이제, 적극, 대안, 요구,...    No\n",
       "4  [악질, 세, 입자, 방지, 를, 위, 한, 세, 입자, 보호, 법, 을, 재정, ...   Yes"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop = df[['token_final', 'label']]\n",
    "df_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop.to_csv('data/df_drop.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec 임베딩 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=42642, vector_size=100, alpha=0.025>\n",
      "[('음주', 0.859895646572113), ('뺑소니', 0.8204270601272583), ('무면허', 0.8194722533226013), ('살인자', 0.763842761516571), ('살인죄', 0.7449493408203125), ('전과자', 0.7433609962463379), ('윤창', 0.7320032119750977), ('운전자', 0.7306980490684509), ('강력범죄', 0.7239797115325928), ('경범죄', 0.7230558395385742)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "embedding_model = Word2Vec(df_drop['token_final'], \n",
    "                           sg = 1, # skip-gram\n",
    "                           vector_size=100, \n",
    "                           window = 2, \n",
    "                           min_count = 1, \n",
    "                           workers = 4\n",
    "                           )\n",
    "\n",
    "print(embedding_model)\n",
    "\n",
    "# 단어 유사도 확인\n",
    "model_result = embedding_model.wv.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('음주', 0.859895646572113), ('뺑소니', 0.8204270601272583), ('무면허', 0.8194722533226013), ('살인자', 0.763842761516571), ('살인죄', 0.7449493408203125), ('전과자', 0.7433609962463379), ('윤창', 0.7320032119750977), ('운전자', 0.7306980490684509), ('강력범죄', 0.7239797115325928), ('경범죄', 0.7230558395385742)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 임베딩 모델 저장 및 로드\n",
    "embedding_model.wv.save_word2vec_format('data/petitions_tokens_w2v') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format('data/petitions_tokens_w2v') # 모델 로드\n",
    "\n",
    "# 로드된 모델로 단어 유사도 확인\n",
    "model_result = loaded_model.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Split 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "rng = RandomState()\n",
    "\n",
    "tr = df_drop.sample(frac=0.8, random_state=rng)\n",
    "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
    "\n",
    "tr.to_csv('data/train.csv', index=False, encoding='utf-8-sig')\n",
    "val.to_csv('data/validation.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.6.0 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchtext==0.6.0) (4.66.4)\n",
      "Requirement already satisfied: requests in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchtext==0.6.0) (2.32.3)\n",
      "Requirement already satisfied: torch in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchtext==0.6.0) (2.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchtext==0.6.0) (1.24.4)\n",
      "Requirement already satisfied: six in c:\\users\\pknu\\appdata\\roaming\\python\\python38\\site-packages (from torchtext==0.6.0) (1.16.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchtext==0.6.0) (0.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->torchtext==0.6.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->torchtext==0.6.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->torchtext==0.6.0) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->torchtext==0.6.0) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->torchtext==0.6.0) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->torchtext==0.6.0) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->torchtext==0.6.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->torchtext==0.6.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->torchtext==0.6.0) (2024.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pknu\\appdata\\roaming\\python\\python38\\site-packages (from tqdm->torchtext==0.6.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pknu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torchtext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import Field\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('[\\[\\]\\']', '', str(text))\n",
    "    text = text.split(', ')\n",
    "    return text\n",
    "\n",
    "TEXT = Field(tokenize=tokenizer)\n",
    "LABEL = Field(sequential = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['임대차', '3', '법', '으로', '인한', '일시', '적', '2', '주택', '기간', '연장', '을', '요구', '합니다', '저', '법', '테두리', '안', '일시', '주택', '상황', '사람', '최근', '임대차', '법', '시행', '세상', '입대', '인과', '임차', '기본', '임대', '적폐', '간주', '법', '문제', '가장', '먼저', '문제', '임차', '임대', '적', '생각', '이로', '임대', '집', '팔지', '방해', '하자', '움직임', '인터넷', '통해', '확산', '팔지', '자신', '더', '연장', '수', '때문', '일시', '주택', '사람', '시기', '안', '집', '처분', '임차', '방해', '집', '팔지', '이건', '뉴', '이', '법안', '효과', '위', '부작용', '제대로', '후', '임차', '집', '팔지', '경우', '임차', '그', '손해', '배상하', '거나', '일시', '주택', '기간', '연장', '것', '요구'] No\n",
      "Validation: ['필리핀', '인도네시아', '베트남', '무비', '자', '제주도', '관광', '입국', '과', '내륙', '5일', '체류', '반대', '합니다', '국민', '의견', '미래', '제대로', '보지', '못', '졸속', '선심', '외교', '정책', '방안', '제주', '도정', '추산', '불법', '중국인', '취업', '제주도', '법무부', '추산', '불법', '체류', '노동자', '현실', '관광', '제주', '목표', '제주', '특별자치도', '무비', '허용', '불법체류', '중국인', '중국', '눈치', '불법', '중국', '처리', '젠', '동남아', '이번', '조치', '그냥', '한국인', '보호', '니', '불법', '체류', '노동', '하라', '승인', '필리핀', '베트남', '인도네시아', '길', '터주', '미얀마', '캄보디아', '말레이시아', '라오스', '태국', '타당', '한번', '되돌리기', '저', '출산율', '외국인', '해도', '좀더', '우리', '시간', '무분별', '그', '통행', '불법', '체류', '고용', '자', '차라리', '동남아', '각국', '엘리트', '산업', '연수', '합법', '범위', '내', '대폭', '확대', '일단', '후', '한국', '나라', '인재', '교육', '데리', '또한', '민족', '정체', '훼손', '그', '가족', '수용', '불법', '체류', '노동자', '법무부', '경찰청', '확대', '수사권', '대한민국', '미래', '꼭', '우리', '후진국', '사람', '필요', '우리', '나라', '한국', '고용', '시장', '개방', '기업', '탈', '한국', '다시', '한번', '금번', '동남아', '국', '제주도', '내륙', '무비', '체류', '반대', '대신', '산업', '수생', '확대', '그', '대처', '방안'] No\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "train, validation = TabularDataset.splits(\n",
    "    path = 'data/',\n",
    "    train = 'train.csv',\n",
    "    validation = 'validation.csv',\n",
    "    format = 'csv',\n",
    "    fields = [('text', TEXT), ('label', LABEL)],\n",
    "    skip_header = True\n",
    ")\n",
    "\n",
    "print(\"Train:\", train[0].text,  train[0].label)\n",
    "print(\"Validation:\", validation[0].text, validation[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PKNU\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchtext\\vocab.py:432: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.itos, self.stoi, self.vectors, self.dim = torch.load(path_pt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터의 개수와 차원 : torch.Size([39052, 100]) \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "vectors = Vectors(name=\"data/petitions_tokens_w2v\")\n",
    "\n",
    "TEXT.build_vocab(train, vectors = vectors, min_freq = 1, max_size = None)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "vocab = TEXT.vocab\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iter, validation_iter = BucketIterator.splits(\n",
    "    datasets = (train, validation),\n",
    "    batch_size = 8,\n",
    "    device = device,\n",
    "    sort = False\n",
    ")\n",
    "\n",
    "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextCNN Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn   \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class TextCNN(nn.Module): \n",
    "    \n",
    "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
    "        \n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab_built.vectors)      \n",
    "    \n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
    "        self.relu = nn.ReLU()                \n",
    "        self.dropout = nn.Dropout(0.4)         \n",
    "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)     \n",
    "        \n",
    "    def forward(self, x):  \n",
    "      \n",
    "        emb_x = self.embed(x)           \n",
    "        emb_x = emb_x.unsqueeze(1)  \n",
    "\n",
    "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]       \n",
    "\n",
    "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]    \n",
    "        \n",
    "        fc_x = torch.cat(pool_x, dim=1) \n",
    "        fc_x = fc_x.squeeze(-1)       \n",
    "        fc_x = self.dropout(fc_x)         \n",
    "\n",
    "        logit = self.fc(fc_x)     \n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_itr, optimizer):\n",
    "    \n",
    "    model.train()                               \n",
    "    corrects, train_loss = 0.0,0        \n",
    "    \n",
    "    for batch in train_itr:\n",
    "        \n",
    "        text, target = batch.text, batch.label      \n",
    "        text = torch.transpose(text, 0, 1)          \n",
    "        target.data.sub_(1)                                 \n",
    "        text, target = text.to(device), target.to(device)  \n",
    "\n",
    "        optimizer.zero_grad()                           \n",
    "        logit = model(text)                         \n",
    "    \n",
    "        loss = F.cross_entropy(logit, target)   \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "        train_loss += loss.item()    \n",
    "        result = torch.max(logit,1)[1] \n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "        \n",
    "    train_loss /= len(train_itr.dataset)\n",
    "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
    "\n",
    "    return train_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, itr):\n",
    "    \n",
    "    model.eval()\n",
    "    corrects, test_loss = 0.0, 0\n",
    "\n",
    "    for batch in itr:\n",
    "        \n",
    "        text = batch.text\n",
    "        target = batch.label\n",
    "        text = torch.transpose(text, 0, 1)\n",
    "        target.data.sub_(1)\n",
    "        text, target = text.to(device), target.to(device)\n",
    "        \n",
    "        logit = model(text)\n",
    "        loss = F.cross_entropy(logit, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        result = torch.max(logit,1)[1]\n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "\n",
    "    test_loss /= len(itr.dataset) \n",
    "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training 및 performance 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN(\n",
      "  (embed): Embedding(39052, 100)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 10, kernel_size=(3, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 10, kernel_size=(4, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 10, kernel_size=(5, 100), stride=(1, 1))\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=30, out_features=2, bias=True)\n",
      ")\n",
      "Train Epoch: 1 \t Loss: 0.08239566498553184 \t Accuracy: 61.55083465576172%\n",
      "Valid Epoch: 1 \t Loss: 0.07838527467923567 \t Accuracy: 65.76287078857422%\n",
      "model saves at 65.76287078857422 accuracy\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 2 \t Loss: 0.07523348232852119 \t Accuracy: 67.8690414428711%\n",
      "Valid Epoch: 2 \t Loss: 0.07891998212674961 \t Accuracy: 64.52205657958984%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 3 \t Loss: 0.06632367605487893 \t Accuracy: 74.07237243652344%\n",
      "Valid Epoch: 3 \t Loss: 0.07583265331135515 \t Accuracy: 67.96875%\n",
      "model saves at 67.96875 accuracy\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = TextCNN(vocab, 100, 10, [3, 4, 5], 2).to(device)\n",
    "print(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_test_acc = -1\n",
    "\n",
    "for epoch in range(1, 3+1):\n",
    " \n",
    "    tr_loss, tr_acc = train(model, device, train_iter, optimizer) \n",
    "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
    "    \n",
    "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
    "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
    "        \n",
    "    if val_acc > best_test_acc:\n",
    "        best_test_acc = val_acc\n",
    "        \n",
    "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
    "        torch.save(model.state_dict(), \"TextCNN_Best_Validation\")\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
